{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b651d61",
   "metadata": {},
   "source": [
    "### Chow test (forecast) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631fc49",
   "metadata": {},
   "source": [
    "If we're able to split our data as **in-sample** and **out-of-sample**, we can test whether we can use the in-sample to calculate the effects and use those estimators to obtain a reliable forecast in the out-of-sample. To do this, assume our data is generated by the following DGP:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "y_{1, n \\times 1} \\\\\n",
    "y_{2, g \\times 1}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "X_{1, n \\times k} & 0_{n \\times g} \\\\\n",
    "X_{2, g \\times k} & I_g \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\beta_{k \\times 1} \\\\\n",
    "\\gamma_{g \\times 1}\n",
    "\\end{bmatrix}+\n",
    "\\begin{bmatrix}\n",
    "\\epsilon_{1, n \\times 1} \\\\\n",
    "\\epsilon_{2, g \\times 1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The hypothesis to be tested is $H_0: \\gamma = 0$, $H_a: \\gamma \\neq 0$. Why? $\\gamma$ can be understood as the **forecast errors**.  If $\\gamma \\neq 0$, we need the **full** sample to reliably estimate $\\beta$ (otherwise we will have ommited variable bias).\n",
    "\n",
    "***\n",
    "\n",
    "Our estimated model will be:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "y_{1, n \\times 1} \\\\\n",
    "y_{2, g \\times 1}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "X_{1, n \\times k} & 0_{n \\times g} \\\\\n",
    "X_{2, g \\times k} & I_g \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_{k \\times 1} \\\\\n",
    "c_{g \\times 1}\n",
    "\\end{bmatrix}+\n",
    "\\begin{bmatrix}\n",
    "e_{1, n \\times 1} \\\\\n",
    "e_{2, g \\times 1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Which implies:\n",
    "\n",
    "\\begin{align}\n",
    "    y_{1, n \\times 1} &= X_{1, n \\times k}b_{k \\times 1} + e_{1, n \\times 1}  \\\\\n",
    "    y_{2, g \\times 1} &= X_{2, g \\times k}b_{k \\times 1} + c_{g \\times 1} + e_{2, g \\times 1}\n",
    "\\end{align}\n",
    "\n",
    "The criterion function will be the sum of squares of the errors:\n",
    "\n",
    "$$S(b,c)= SSR = e_{1}^Te_{1} + e_{2}^Te_{2} = (y_{1} - X_{1}b)^T(y_{1} - X_{1}b) + (y_{2} - X_{2}b - c)^T(y_{2} - X_{2}b - c) $$\n",
    "\n",
    "Under $H_0: \\gamma = 0$ (**restricted model**), our $SSR$ becomes\n",
    "\n",
    "$$SSR_R = (y_{1} - X_{1}b_R)^T(y_{1} - X_{1}b_R) + (y_{2} - X_{2}b_R)^T(y_{2} - X_{2}b_R) $$\n",
    "\n",
    "The $SSR$ is calculated with the residuals of an OLS model that uses the full sample data ($X1$ and $X2$).\n",
    "\n",
    "Under $H_a : \\gamma \\neq 0 $ (**non restricted model**), our $SSR$ becomes\n",
    "\n",
    "$$ SSR = (y_{1} - X_{1}b)^T(y_{1} - X_{1}b) + (y_{2} - X_{2}b - c)^T(y_{2} - X_{2}b - c) $$\n",
    "\n",
    "Take the derivative with respect to $c$:\n",
    "\n",
    "$$ \\frac{dSSR}{dc} = -(y_{2} - X_{2}b - c) = 0 $$\n",
    "\n",
    "The $SSR$ becomes \n",
    "\n",
    "$$ SSR = (y_{1} - X_{1}b)^T(y_{1} - X_{1}b) $$\n",
    "\n",
    "The $SSR$ is calculated with the residuals of an OLS model that only uses the in-sample data $X_1$. If there is a forecast error, it will \"absorb\" the $SSR$ in the out-of-sample. It seems counterintuitive, but we need the $SSR$ to be high so we can conclude that there is no forecast errors reducing it.\n",
    "\n",
    "In both cases, we only estimate the vector $b_{k \\times 1}$, so we need to take the inverse of a matrix with dimensions $k \\times k$. This is more convenient than trying to evaluate the forecast errors, which would need the inverse of a $g \\times g$ matrix.\n",
    "\n",
    "***\n",
    "\n",
    "For the $F$ statistic: The degrees of freedom for the Chow test are $g$, because $\\gamma$ is a $g \\times 1$ vector (the variables being restricted), and $n+g$ rows minus $k+g$ estimators in the unrestricted model: $n-k$. \n",
    "\n",
    "$$F = \\frac{(SSR_R - SSR)/g}{SSR/(n-k)}   $$\n",
    "\n",
    "Note that this works only becase we make the assumption that\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "\\epsilon_{1, n \\times 1} \\\\\n",
    "\\epsilon_{2, g \\times 1}\n",
    "\\end{bmatrix} \\sim N_{n+g}(0, \\sigma^2I_{n+g})\n",
    "$$\n",
    "\n",
    "And therefore we can use our previously derived $F$ statistic that eliminates the unknown $\\sigma$ parameter.\n",
    "\n",
    "\n",
    "***\n",
    "**Conclusion:**\n",
    "\n",
    "To test whether we can use only the in-sample to calculate the effects and use those estimators to obtain a reliable forecast in the out-of-sample, compare how much does the $SSR$ increase for imposing the \"restriction\" that we can forecast the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9ffc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563d37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
