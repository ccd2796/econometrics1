{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c823cc2f",
   "metadata": {},
   "source": [
    "### 1. Linear Model ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc96f9e",
   "metadata": {},
   "source": [
    "Consider a vector $y_{n \\times 1}$ (**dependent, endogenous**) that we will try to explain using the information contained in a matrix $X_{n\\times k}$ (**independent, exogenous**). We assume a linear relationship between $X$ and $y$, measured by $k$ effects stored in $b_{k\\times 1}$. There will be an estimation error $e_{n \\times 1}$ (**residuals**). Note that we are not yet using any of the seven assumptions.\n",
    "\n",
    "$$ y = Xb + e  $$\n",
    "\n",
    "The criteria to call this a \"good\" regression is to consider some \"criterion function\" that depends on the residuals. \n",
    "\n",
    "$$S(b) = f(e)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d509311",
   "metadata": {},
   "source": [
    "### 2. OLS ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5e9a6",
   "metadata": {},
   "source": [
    "OLS considers the criterion function to be sum of squares of the residuals. This also represents the square of the norm of the residual vector:\n",
    "\n",
    "$$S(b) = \\sum_n e_i^2 = e^Te = \\|e \\|^2 $$\n",
    "\n",
    "Minimizing:\n",
    "\n",
    "$$S(b) = e^Te = (y - Xb)^T(y - Xb) $$\n",
    "\n",
    "$$\\frac{dS(b)}{db} = 2(y - Xb)^TX = 0 = X^T(y - Xb) $$\n",
    "\n",
    "Obtaning the **normal equations**, this is the set of equations to be solved:\n",
    "\n",
    "$$ X^Ty = X^TXb$$\n",
    "\n",
    "Granted that $X^TX$ has full rank, solving for $b$:\n",
    "\n",
    "$$ b = (X^TX)^{-1}X^Ty  $$\n",
    "\n",
    "As a side note, using the normal equations and replacing $y$ by the linear model\n",
    "\n",
    "$$ X^Ty = X^T(Xb + e)= X^TXb + X^Te = X^TXb \\quad \\text{then, $X^Te =0$}$$\n",
    "\n",
    "If $X$ has a column of ones, meaning that this model has an intercept, it follows that $i^Te = 0$ and $\\bar{e}=0$. This implies that the covariance between the columns of $X$ and $e$ can be evaluated by $X^Te$, which is always 0. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300dc47",
   "metadata": {},
   "source": [
    "### 3. Geometrical properties ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a7941",
   "metadata": {},
   "source": [
    "Replacing the estimated $b$ in the linear model:\n",
    "\n",
    "$$ y = Xb + e = y + X(X^TX)^{-1}X^Ty + e $$\n",
    "\n",
    "Defining $H = X(X^TX)^{-1}X^T$ we check that this matrix projects a vector on the column space of $X$. What is the dimension of this space?\n",
    "\n",
    "$$rank(H) = Tr(H) = Tr(X(X^TX)^{-1}X^T) = Tr((X^TX)^{-1}X^TX) = Tr(I_k) = k $$\n",
    "\n",
    "The estimated values of $y$ are in the column space of $X$, which is lower dimensional. Then, the residual vector $e$ can be obtained by another projection of $y$ using the matrix $M=I-H$, a $n-k$ dimensional space orthogonal to $X$. This is why it is said that **the residuals of the estimation have n-k degrees of freedom**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf4389",
   "metadata": {},
   "source": [
    "### R squared ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c72b2",
   "metadata": {},
   "source": [
    "Trying to decompose the explained variance of $y$. We can find the sum of squares of $y$ by using the projection matrix $M = I - \\frac{ii^T}{i^Ti} $ that calculates the mean deviated vector $y - \\bar{y}$. The sum of squares of $y$ will be:\n",
    "\n",
    "$$\\sum_n (y_i-\\bar{y})^2 = y^T M y $$\n",
    "\n",
    "$$y = Xb + e $$\n",
    "\n",
    "$$My = MXb + Me $$\n",
    "\n",
    "$$y^TMy = MXb + Me $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba58a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45386841",
   "metadata": {},
   "source": [
    "### 4. Statistical properties of b ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06231c6",
   "metadata": {},
   "source": [
    "The estimator $b$ is a random variable. What can we say about its properties? (note the use of $\\stackrel{\\text{A*}}{=}$ to highlight the assumption used)\n",
    "\n",
    "$$b = (X^TX)^{-1}X^Ty \\stackrel{\\text{A6}}{=} (X^TX)^{-1}X^T( X\\beta  + \\epsilon) = \\beta + (X^TX)^{-1}X^T\\epsilon $$\n",
    "\n",
    "**Expectation:**\n",
    "\n",
    "$$ E[b] = \\beta + E[(X^TX)^{-1}X^T\\epsilon] \\stackrel{\\text{A1}}{=} \\beta + (X^TX)^{-1}X^TE[\\epsilon]  \\stackrel{\\text{A2}}{=} \\beta   $$\n",
    "\n",
    "Under assumptions, $b$ is unbiased.\n",
    "\n",
    "\n",
    "**Variance:**\n",
    "\n",
    "$$ Var(b) = E[(b-E[b])(b-E[b])^T] = E[(b-\\beta)(b-\\beta)^T] = E[ (X^TX)^{-1}X^T\\epsilon \\epsilon^T X (X^TX)^{-1}]  $$\n",
    "\n",
    "$$E[ (X^TX)^{-1}X^T\\epsilon \\epsilon^T X (X^TX)^{-1}]  \\stackrel{\\text{A1}}{=}  (X^TX)^{-1}X^TE[\\epsilon \\epsilon^T] X (X^TX)^{-1} $$\n",
    "\n",
    "$$ (X^TX)^{-1}X^TE[\\epsilon \\epsilon^T] X (X^TX)^{-1}  \\stackrel{\\text{A3,A4}}{=}  \\sigma^2(X^TX)^{-1}  $$\n",
    "\n",
    "Under assumptions, variance of $b$ is.\n",
    "\n",
    "$$ Var(b) = \\sigma^2(X^TX)^{-1} $$\n",
    "\n",
    "The diagonal elements contain the variance of the estimators $b_j$, and the off diagonal represent the covariance between estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f9b48",
   "metadata": {},
   "source": [
    "### 5. Distribution of e ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300c9ad",
   "metadata": {},
   "source": [
    "Recall that $e$ can be constructed from $y$ by projecting it using the $M$ matrix, with $rank(M)=n-k$ (note the use of $\\stackrel{\\text{A*}}{=}$ to highlight the assumption used)\n",
    "\n",
    "$$ e = My \\stackrel{\\text{A6}}{=} M(X\\beta + \\epsilon) = (I-H) X\\beta + M\\epsilon $$\n",
    "\n",
    "Naturally, projecting $X$ on its own column space will yield $X$\n",
    "\n",
    "$$ e = (X-X)\\beta + M\\epsilon = M\\epsilon $$\n",
    "\n",
    "This means that, under assumption 6, the residual vector is a projection of the disturbances. This space has $n-k$ degrees of freedom.\n",
    "\n",
    "Furthermore, using assumption 2-4, and 7:\n",
    "\n",
    "$$\\epsilon \\sim N_n(0, \\sigma^2I_n) $$\n",
    "\n",
    "$$ e = M\\epsilon \\sim N_n(0, \\sigma^2M) $$\n",
    "\n",
    "The residual vector $e$ follows a degenerate normal distribution. However, we can find a distribution for the squared norm of this vector. Using previous results:\n",
    "\n",
    "$$ \\frac{\\epsilon}{\\sigma} \\sim N_n(0, I_n)  $$\n",
    "\n",
    "\n",
    "$$ e^Te = (M\\epsilon)^TM\\epsilon = \\epsilon^T M \\epsilon $$\n",
    "\n",
    "Dividing both sides by $\\sigma^2$\n",
    "\n",
    "$$ \\frac{e^Te}{\\sigma^2} = \\frac{\\epsilon}{\\sigma}^TM\\frac{\\epsilon}{\\sigma} \\sim \\chi^2(n-k) \\quad \\text{, given that $rank(M)=n-k$} $$\n",
    "\n",
    "Then, $\\frac{e^Te}{\\sigma^2}$ follows a $ \\chi^2(n-k)$ distribution. Recall that the expected value of a Chi squared distribution with $r$ degrees of freedom is $r$ \n",
    "\n",
    "$$ E\\Bigg[ \\frac{e^Te}{\\sigma^2}   \\Bigg] = n-k $$\n",
    "\n",
    "$$ E\\Bigg[ \\frac{e^Te}{n-k}   \\Bigg] = \\sigma^2 $$\n",
    "\n",
    "An unbiased estimator of $\\sigma^2$ is $s^2 = \\frac{\\sum_n e_i^2}{n-k} = \\frac{e^Te}{n-k}$, the sample variance of the residuals, adjusted by $n-k$ degrees of freedom. This also could be seen as the squared norm of the residuals vector, rescaled by its degrees of freedom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c205b",
   "metadata": {},
   "source": [
    "### T-statistic ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da27139",
   "metadata": {},
   "source": [
    "In order to make hypothesis testing, or calculating confidence intervals, we need to find a pivotal quantity for $b$. This will be possible if we notice that under some assumptions:\n",
    "\n",
    "$$b = \\beta + (X^TX)^{-1}X^T\\epsilon \\quad \\text{, where $\\epsilon \\sim N_n(0, \\sigma^2I_n)$}$$\n",
    "\n",
    "$$b - \\beta =  (X^TX)^{-1}X^T\\epsilon \\sim N_k(0, \\sigma^2(X^TX)^{-1})$$\n",
    "\n",
    "$$b - \\beta   \\sim N_k(0, \\sigma^2(X^TX)^{-1}) = N_k(0, Var(b)) $$\n",
    "\n",
    "For a particular element of the vector $b_j$ and for $Var(b_j) = \\sigma^2 [(X^TX)^{-1}]_{jj} =  \\sigma^2 B_{jj}$\n",
    "\n",
    "$$b_j - \\beta_j   \\sim N(0, \\sigma^2 B_{jj})$$\n",
    "\n",
    "$$\\frac{b_j - \\beta_j}{\\sigma \\sqrt{B_{jj}} }   \\sim N(0, 1)$$\n",
    "\n",
    "We would construct our intervals and tests with this using the $N(0,1)$ distribution, but notice that this is not yet a pivotal quantity, because there is an unknown $\\sigma$ parameter. To solve this, we will divide by a rescaled Chi squared, which results in a $T$ random variable.\n",
    "\n",
    "For a $N \\sim N(0,1)$ normal random variable and a $X \\sim \\chi^2(k)$ Chi squared random variable:\n",
    "\n",
    "$$ T(k) = \\frac{N}{\\sqrt{X/k}} \\quad \\text{, a $T$ distribution with $k$ degrees of freedom} $$\n",
    "\n",
    "We will use $\\frac{e^Te}{\\sigma^2}$ , which we know from previous results that follows a $ \\chi^2(n-k)$ distribution. Then $\\frac{e^Te}{\\sigma^2}\\times \\frac{1}{n-k} = \\frac{s^2}{\\sigma^2} $. Taking square root and dividing:\n",
    "\n",
    "$$ \\frac{b_j - \\beta_j}{\\sigma \\sqrt{B_{jj}} } \\times \\frac{\\sigma}{s}  = \\frac{b_j - \\beta_j}{s \\sqrt{B_{jj}} } \\sim T(n-k) $$\n",
    "\n",
    "Which is the pivotal quantity that we will use for testing and confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce0ee6",
   "metadata": {},
   "source": [
    "### Restricted regressions ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925904d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec01b71",
   "metadata": {},
   "source": [
    "### F-statistic ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be0b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e60c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad55a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
