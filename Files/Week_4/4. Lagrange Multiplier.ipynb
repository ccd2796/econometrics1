{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ce5814",
   "metadata": {},
   "source": [
    "### 1. Recap ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfce82",
   "metadata": {},
   "source": [
    "**Recap from week 3: Test**\n",
    "\n",
    "Recall that the null hypothesis was formulated as:\n",
    "\n",
    "$$H_0 : R \\beta = r$$\n",
    "\n",
    "$$H_0 : R \\beta - r= 0$$\n",
    "\n",
    "Under the null hypothesis our test statistic comes from a $\\chi^2(g)$ distribution\n",
    "\n",
    "$$\\frac{(Rb - r)^TC^{-1}(Rb - r)}{\\sigma^2} \\sim \\chi^2(g)$$\n",
    "\n",
    "Where $C = R(X^TX)^{-1}R^T$\n",
    "\n",
    "***\n",
    "\n",
    "**Recap from week 3: Constrained regression**\n",
    " \n",
    "The minimization of the constrained problem is\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& \\underset{b_R}{\\text{minimize}}\n",
    "& & S(b_R) = (y-Xb_R)^T(y-Xb_R) \\\\\n",
    "& \\text{subject to}\n",
    "& &  g(b_R) = Rb_R - r =0.\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "The Karush-Kuhn-Tucker conditions are:\n",
    "\n",
    "$$\\nabla S(b_R) = \\nabla g(b_R) \\lambda $$\n",
    "\n",
    "$$g(b_R) =0  $$\n",
    "\n",
    "From the first order conditions we got that\n",
    "\n",
    "$$\\lambda = (R(X^TX)^{-1}R^T)^{-1}(Rb - r) = C^{-1}(Rb - r) \\quad \\text{where $C = R(X^TX)^{-1}R^T$} $$\n",
    "\n",
    "From here we can already see that $\\lambda$ will be close to $0$ if $Rb$ is close to $r$\n",
    "\n",
    "Another result found about the relationship between $e_R$ and $e$\n",
    "\n",
    "$$ e_R = e + X(X^TX)^{-1}R^T(R(X^TX)^{-1}R^T)^{-1}(Rb - r)$$\n",
    "\n",
    "Using the fact that $X^Te = 0$\n",
    "\n",
    "$$ X^Te_R = X^Te + X^TX(X^TX)^{-1}R^T(R(X^TX)^{-1}R^T)^{-1}(Rb - r) $$\n",
    "\n",
    "$$ X^Te_R = R^T(R(X^TX)^{-1}R^T)^{-1}(Rb - r) $$\n",
    "\n",
    "$$ X^Te_R = R^T\\lambda $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8077d",
   "metadata": {},
   "source": [
    "### 2. Lagrange multiplier test ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb78eba",
   "metadata": {},
   "source": [
    "$C$ is symmetric, we can replace in the test statistic\n",
    "\n",
    "$$\\frac{(Rb - r)^TC^{-1}(Rb - r)}{\\sigma^2} = \\frac{(Rb - r)^T C^{-1} C C^{-1}(Rb - r)}{\\sigma^2} = \\frac{\\lambda^T C\\lambda}{\\sigma^2}$$\n",
    "\n",
    "Testing the hypothesis $H_0 : R\\beta = r$ is the same as testing if our modified test statistic comes from a $\\chi^2(g)$ distribution\n",
    "\n",
    "$$\\frac{\\lambda^T R(X^TX)^{-1}R^T \\lambda}{\\sigma^2}$$\n",
    "\n",
    "Where $\\lambda = (R(X^TX)^{-1}R^T)^{-1}(Rb - r) $\n",
    "\n",
    "To facilitate the construction of the auxiliary regression test statistic, $\\sigma^2$ is replaced by the **biased** estimator $\\hat{\\sigma}^2 = e_R^Te_R/n$\n",
    "\n",
    "Then, the lagrange multiplier test statistic under the null becomes **approximately** Chi squared. Previously it was derived as an exact $F$ distribution, but given that the denominator isn't a Chi squared divided by its degrees of freedom (but something similar), this is close to a Chi squared.\n",
    "\n",
    "$$LM = \\frac{\\lambda^T R(X^TX)^{-1}R^T \\lambda}{\\hat{\\sigma}^2} \\approx \\chi^2(g) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6b6a3",
   "metadata": {},
   "source": [
    "### 3. Auxiliary regression ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89aabc",
   "metadata": {},
   "source": [
    "Replacing $ X^Te_R = R^T\\lambda $ in the test statistic\n",
    "\n",
    "$$LM = \\frac{\\lambda^T R(X^TX)^{-1}R^T \\lambda}{\\hat{\\sigma}^2} = n\\frac{e_R^T X (X^TX)^{-1}X^Te_R}{e_R^Te_R} $$\n",
    "\n",
    "If we define the auxiliary regression on the residuals of the restricted model against our complete set of regressors in $X$\n",
    "\n",
    "$$ e_R = X\\delta + \\omega $$\n",
    "\n",
    "And estimate it using OLS\n",
    "\n",
    "$$ \\delta_{OLS} = (X^TX)^{-1}X^Te_R $$\n",
    "\n",
    "Denote the projection matrix on the column space of $X$, $H = X(X^TX)^{-1}X^T$\n",
    "\n",
    "$$LM = n\\frac{e_R^T X (X^TX)^{-1}X^Te_R}{e_R^Te_R} = n\\frac{e_R^T H^T H e_R}{e_R^Te_R}  $$\n",
    "\n",
    "If the original model had an intercept, then $\\bar{e_R} = 0 $ and $SST = e_R^Te_R$, $SSE = e_R^T H^T H e_R$ (check $R^2$ in Week 3). The test statistic becomes\n",
    "\n",
    "$$LM = n\\frac{e_R^T H^T H e_R}{e_R^Te_R} =n\\frac{SSE}{SST}  = nR^2 $$\n",
    "\n",
    "Finally, testing the hypothesis $H_0 : R\\beta = r$ is the same as testing if our lagrange multiplier test statistic comes from an **approximate** $\\chi^2(g)$ distribution\n",
    "\n",
    "$$LM = nR^2  \\approx \\chi^2(g) $$\n",
    "\n",
    "Where $R^2$ is calculated on the auxiliary regression of the residuals of the constrained model (under the null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796fc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
